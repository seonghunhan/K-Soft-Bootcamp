{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python과 Pandas를 이용한 데이터프레임 처리\n",
    "![](https://i.imgur.com/zfxLzEv.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 장에서는 다음과 같은 주제들을 다룹니다:\n",
    "\n",
    "- CSV파일을 판다스(Pandas) 데이터 프레임으로 읽기\n",
    "- 판다스 데이터 프라임의 데이터 다루기\n",
    "- 데이터에 쿼리, 정렬, 분석 해보기\n",
    "- 데이터 합치기, 묶기, 집계 수행해보기\n",
    "- 데이터로부터 유용한 정보 추출해보기\n",
    "- 막대 그래프와 꺾은선 그래프 만들어 보기\n",
    "- 데이터를 CSV 파일로 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas를 이용해 CSV 파일 읽기\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) 는 테이블 데이터를 다루기 위해 많이 사용되는 유명한 파이썬 라이브러리입니다. \n",
    "판다스는 CSV, Excel, HTML, JSON, SQL 등과 같은 데이터 파일에 대한 함수들을 지원해줍니다.  \n",
    "이탈리아의 일별 Covid-19 데이터를 담고 있는 `italy-covid-daywise.csv`파일을 다운로드 해보겠습니다.\n",
    "```\n",
    "date,new_cases,new_deaths,new_tests\n",
    "2020-04-21,2256.0,454.0,28095.0\n",
    "2020-04-22,2729.0,534.0,44248.0\n",
    "2020-04-23,3370.0,437.0,37083.0\n",
    "2020-04-24,2646.0,464.0,95273.0\n",
    "2020-04-25,3021.0,420.0,38676.0\n",
    "2020-04-26,2357.0,415.0,24113.0\n",
    "2020-04-27,2324.0,260.0,26678.0\n",
    "2020-04-28,1739.0,333.0,37554.0\n",
    "...\n",
    "```\n",
    "\n",
    "데이터 형식이 CSV로 구성되어 있다는 것을 확인할 수 있습니다.  \n",
    "> **CSV**: CSV 파일은 쉼표를 사용하여 값을 구분하는 텍스트 파일입니다. 파일의 각 줄은 데이터 레코드이며, 각 레코드는 쉼표로 구분된 하나 이상의 필드로 구성됩니다.  \n",
    "CSV 파일은 일반적으로 테이블 데이터(숫자와 텍스트)를 일반 텍스트로 저장하며, 이 경우 각 행은 동일한 수의 필드를 가집니다.\n",
    "<!--\n",
    "> **CSVs**: A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas. A CSV file typically stores tabular data (numbers and text) in plain text, in which case each line will have the same number of fields. (Wikipedia)\n",
    "-->\n",
    "\n",
    "다운로드는  `urllib.request`라이브러리의 `urlretrieve` 함수를 이용해서 이전과 같이 수행할 수 있습니다.  \n",
    "하지만, 이번에는 csv 실습 파일을 제공하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일을 읽기 위해서 `Pandas` 라이브러리의 `read_csv`함수를 사용합니다..<br>\n",
    "이를 위해, 먼저 Pandas 라이브러리를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드 셀을 실행했다면, 이제 `pandas` 라이브러리를 사용할 수 있습니다. <br>\n",
    "보통 `pd` 라는 이름으로 사용하므로, 우리도 그렇게 사용하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = pd.read_csv('italy-covid-daywise.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일에서 읽어온 데이터는 `DataFrame` 형태로 저장됩니다.<br>\n",
    "> `DataFrame`: Pandas의 테이블 데이터를 저장하는 핵심 자료구조 중 하나로, 보통 `_df` 라는 접미를 변수명에 넣어서 데이터프레임인 것을 명시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(covid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>996.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>975.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  new_cases  new_deaths  new_tests\n",
       "0    2019-12-31        0.0         0.0        NaN\n",
       "1    2020-01-01        0.0         0.0        NaN\n",
       "2    2020-01-02        0.0         0.0        NaN\n",
       "3    2020-01-03        0.0         0.0        NaN\n",
       "4    2020-01-04        0.0         0.0        NaN\n",
       "..          ...        ...         ...        ...\n",
       "243  2020-08-30     1444.0         1.0    53541.0\n",
       "244  2020-08-31     1365.0         4.0    42583.0\n",
       "245  2020-09-01      996.0         6.0    54395.0\n",
       "246  2020-09-02      975.0         8.0        NaN\n",
       "247  2020-09-03     1326.0         6.0        NaN\n",
       "\n",
       "[248 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 프레임을 훝어보는 것으로 알 수 있는 것들:\n",
    "\n",
    "- 파일은 이탈리아의 4가지 일별 코로나 데이터를 가지고 있다.\n",
    "- 표는 신규 확진자, 사망자, 검사자 로 구성되어 있다.\n",
    "- 데이터는 248일 분량으로 구성되어 있으며 2019년 12월부터 2020년 9월까지 이다.\n",
    "\n",
    "공시적으로 보고된 통계치지만, 실제 사망자와 확진자는 더 많을 수도 있습니다. <br>\n",
    "\n",
    "`info`함수를 사용한다면 몇가지 기본적인 정보들을 추가적으로 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 248 entries, 0 to 247\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        248 non-null    object \n",
      " 1   new_cases   248 non-null    float64\n",
      " 2   new_deaths  248 non-null    float64\n",
      " 3   new_tests   135 non-null    float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "covid_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각의 열은 특정 날자에 대한 값을 가지고 있는 것으로 추측할 수 있습니다.<br>\n",
    "`.describe`를 활용하면, 수치 데이터로 구성된 열들에 대해서는 요약 통계정보를 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>248.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>135.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1094.818548</td>\n",
       "      <td>143.133065</td>\n",
       "      <td>31699.674074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1554.508002</td>\n",
       "      <td>227.105538</td>\n",
       "      <td>11622.209757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-148.000000</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>7841.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25259.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>342.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>29545.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1371.750000</td>\n",
       "      <td>175.250000</td>\n",
       "      <td>37711.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6557.000000</td>\n",
       "      <td>971.000000</td>\n",
       "      <td>95273.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         new_cases  new_deaths     new_tests\n",
       "count   248.000000  248.000000    135.000000\n",
       "mean   1094.818548  143.133065  31699.674074\n",
       "std    1554.508002  227.105538  11622.209757\n",
       "min    -148.000000  -31.000000   7841.000000\n",
       "25%     123.000000    3.000000  25259.000000\n",
       "50%     342.000000   17.000000  29545.000000\n",
       "75%    1371.750000  175.250000  37711.000000\n",
       "max    6557.000000  971.000000  95273.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`columns` 함수는 데이터의 열 정보를 리스트의 형태로 return 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'new_cases', 'new_deaths', 'new_tests'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.shape`함수는 데이터의 행과 열의 개수를 return 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 확인한 함수와 특성들을 요약하면 다음과 같습니다.\n",
    "\n",
    "* `pd.read_csv` - CSV파일로 부터 데이터를 읽어와 `DataFrame` 형태의 객체로 저장한다.\n",
    "* `.info()` - 행, 열, 데이터 타입과 같은 기본적인 데이터 구조를 확인한다.\n",
    "* `.describe()` - 수치형 데이터에 대한 요약 통계 정보를 확인한다.\n",
    "* `.columns` - 열 이름 정보를 리스트로 가지고 있다.\n",
    "* `.shape` - 행과 열 개수를 튜플 형태로 가지고 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 프레임의 데이터 다루기\n",
    "\n",
    "가장 먼저 하는 일은 특정한 행의 특정한 열의 데이터를 얻는 것처럼 데이터 프레임의 데이터에 접근하는 것입니다. <br>\n",
    "이를 쉽게 하기 위해서는 데이터 프레임의 내부 구조를 이해하는 것이 좋습니다.<br>\n",
    "개념적으로 데이터프레임은 리스트를 가지고 있는 하나의 딕셔너리로 구성되어 있다고 생각하면 되고,<br>\n",
    "키 값은 열 이름이며 각각의 리스트들은 하나의 행을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임은 이런 모양입니다.\n",
    "covid_data_dict = {\n",
    "    'date':       ['2020-08-30', '2020-08-31', '2020-09-01', '2020-09-02', '2020-09-03'],\n",
    "    'new_cases':  [1444, 1365, 996, 975, 1326],\n",
    "    'new_deaths': [1, 4, 6, 8, 6],\n",
    "    'new_tests': [53541, 42583, 54395, None, None]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 데이터를 표현하는 것에는 몇가지 장점이 있습니다.\n",
    "\n",
    "* 하나의 Column(열) 안에 있는 값들은 대부분 같은 데이터 타입을 가지고 있기 떄문에, 하나의 array로 관리하는 것이 좋습니다.\n",
    "* 특정 Row(행)의 데이터에 접근하는 것은 각각의 열에 대해 해당 행의 인덱스로 접근하는 방법으로 행 데이터를 구하는 것입니다.\n",
    "* 이러한 방법은 딕셔너리와 리스트를 함께 사용하는 기존의 방법들 보다 훨씬 간결합니다. (아래와 비교)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임이 이런 모양은 아닙니다.\n",
    "covid_data_list = [\n",
    "    {'date': '2020-08-30', 'new_cases': 1444, 'new_deaths': 1, 'new_tests': 53541},\n",
    "    {'date': '2020-08-31', 'new_cases': 1365, 'new_deaths': 4, 'new_tests': 42583},\n",
    "    {'date': '2020-09-01', 'new_cases': 996, 'new_deaths': 6, 'new_tests': 54395},\n",
    "    {'date': '2020-09-02', 'new_cases': 975, 'new_deaths': 8 },\n",
    "    {'date': '2020-09-03', 'new_cases': 1326, 'new_deaths': 6},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "리스트로 구성된 딕셔너리라는 것을 이해하고 있다면, 데이터프레임에서 데이터에 어떻게 접근하는지 알 수 있을 것입니다.<br>\n",
    "예를 들어, 우리는 특정 열에 행의 인덱스 값을 넣어 데이터에 접근할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1444, 1365, 996, 975, 1326]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data_dict['new_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "        ...  \n",
       "243    1444.0\n",
       "244    1365.0\n",
       "245     996.0\n",
       "246     975.0\n",
       "247    1326.0\n",
       "Name: new_cases, Length: 248, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df['new_cases']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 열들은 `Series`라 불리는 데이터 구조로 표현됩니다.<br>\n",
    "`Series`는 몇가지 추가적인 특성을 가지고 있는 Numpy 배열과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(covid_df['new_cases'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배열과 같이, `[]`와 인덱싱을 통해 특정한 값에 접근할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "975.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df['new_cases'][246]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57640.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df['new_tests'][240]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas는 `at`이라는 함수를 통해, 특정 행과 특정 열에 명시적으로 접근할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "975.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.at[246, 'new_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57640.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.at[240, 'new_tests']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[]` 표기법을 사용하는 것 대신에, 판다스는 열에 접근할때 `.`표기법을 사용할 수 있게 해줍니다.<br>\n",
    "그러나, 이 방법은 열의 이름에 __공백이 있거나 특수문자가 있다면 불가능__ 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "        ...  \n",
       "243    1444.0\n",
       "244    1365.0\n",
       "245     996.0\n",
       "246     975.0\n",
       "247    1326.0\n",
       "Name: new_cases, Length: 248, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.new_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "게다가, `[]`을 이용해 데이터 프레임의 특정 열들로 구성된 하부 데이터셋을 구성할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>new_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>1444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>1365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>1326.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  new_cases\n",
       "0    2019-12-31        0.0\n",
       "1    2020-01-01        0.0\n",
       "2    2020-01-02        0.0\n",
       "3    2020-01-03        0.0\n",
       "4    2020-01-04        0.0\n",
       "..          ...        ...\n",
       "243  2020-08-30     1444.0\n",
       "244  2020-08-31     1365.0\n",
       "245  2020-09-01      996.0\n",
       "246  2020-09-02      975.0\n",
       "247  2020-09-03     1326.0\n",
       "\n",
       "[248 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_df = covid_df[['date', 'new_cases']]\n",
    "cases_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새로운 데이터 프레임인 `casses_df`는 단순히 원본 데이터를 보여주는 역할을 합니다.<br>\n",
    "두 변수에서 데이터는 하나의 메모리에 할당되기 때문에 한 변수에서 데이터에 변화를 주게 되면 다른 쪽에도 영향을 줍니다.<br>\n",
    "이러한 방법은 Pandas를 사용해 대량의 데이터를 처리할 때, 속도를 높이고 메모리의 사용을 줄여준다는 장점이 있습니다.<br>\n",
    "\n",
    "그러나 가끔 독립적인 하부 데이터셋이 필요한 경우도 있는데, 이런 경우 `.copy`함수를 사용해서 깊은 복사를 수행하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df_copy = covid_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`covid_df_copy`안에 있는 데이터들은 `covid_df` 로 부터 완전히 분리된 데이터이며, 값의 변화는 서로 영향을 주지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 잠깐!! Pandas에서 특정 위치의 값을 획득하거나 바꿀 때 사용하는 loc, iloc, iat, at 함수를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 절대 좌표(위치) 지정 | x | o | x  | o  |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 라벨명 지정 | o | x | o | x |\n",
    "| 여러개의 요소 지정 | o | o | x | x |\n",
    "| 슬라이스 표기 | o | o | x | x |\n",
    "\n",
    "\n",
    "**1) 좌표(위치)의 지정 방법**\n",
    "\n",
    "- at, loc : 행 명(행 라벨), 열 명(열 라벨)\n",
    "- iat, iloc : 행 번호, 열 번호(절대 좌표(위치)지정)\n",
    "\n",
    "**2) 선택하여 확인, 변경할 수 있는 데이터**\n",
    "\n",
    "- at, iat : 하나의 요소 값\n",
    "- loc, iloc : 하나 혹은 여러 개의 요소 값\n",
    "- 리스트, 슬라이스로 범위를 지정할 수 있다.\n",
    "- 행, 열을 선택하여 값을 획득하고 변경할 수 있다.\n",
    "\n",
    "**3) 그 외의 차이점**\n",
    "\n",
    "- 처리 속도는 at 과 iat의 경우가 loc과 iloc보다 빠르다\n",
    "- 라벨과 번호를 합쳐서 위치를 지정하고 싶은 경우는 at 혹은 loc과 index나 column을 조합합니다.\n",
    "\n",
    "- at, iat : 하나의 요소 값을 선택, 획득, 변경\n",
    "- loc, iloc : 하나 혹은 여러 개의 요소 값을 선택, 획득, 변경\n",
    "- 하나의 요소 값을 선택\n",
    "- 여러 개의 요소 값을 선택\n",
    "- 행, 열을 선택\n",
    "- 행 명, 열 명이 중복된 값을 가진 경우\n",
    "- 번호와 라벨 단위를 지정\n",
    "- 행을 pandas.Series로 선택할 때 묵시적형 변환\n",
    "\n",
    "참고) pandas.DataFrame의 행, 열, pandas.Series의 요소 값을 선택, 획득하는 경우는 인덱스 참고 df[]도 사용할 수 있습니다. 또한 DataFrame.get_value(), DataFrame.ix[]도 있지만, 둘 다 최신 버전에서는 추천하지 않습니다.\n",
    "\n",
    "이번 샘플 코드에서는 아래의 csv 데이터를 read_csv로 읽어들여 사용합니다. 인수 index_col로 맨 처음의 행을 index로 사용하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age state  point\n",
      "name                     \n",
      "Alice     24    NY     64\n",
      "Bob       42    CA     92\n",
      "Charlie   18    CA     70\n",
      "Dave      68    TX     70\n",
      "Ellen     24    CA     88\n",
      "Frank     30    NY     57\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sample_pandas.normal.csv', index_col=0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice' 'Bob' 'Charlie' 'Dave' 'Ellen' 'Frank']\n",
      "['age' 'state' 'point']\n"
     ]
    }
   ],
   "source": [
    "print(df.index.values)\n",
    "# ['Alice' 'Bob' 'Charlie' 'Dave' 'Ellen' 'Frank']\n",
    "\n",
    "print(df.columns.values)\n",
    "# ['age' 'state' 'point']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **at, iat : 하나의 요소 값을 선택, 획득, 변경**\n",
    "\n",
    "at은 행 명과 열 명으로 위치를 지정한다. 데이터를 획득하기 위할 뿐만 아니라, 그 위치에 새로운 값을 설정(대입)하는 것도 가능합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "TX\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(df.at['Bob', 'age'])\n",
    "print(df.at['Dave', 'state'])\n",
    "# 42\n",
    "# TX\n",
    "\n",
    "df.at['Bob', 'age'] = 60\n",
    "print(df.at['Bob', 'age'])\n",
    "# 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "iat은 행 번호와 열 번호로 위치를 지정합니다. 행 번호, 열 번호는 0부터 시작합니다.\n",
    "\n",
    "iat도 at과 동일하게, 데이터를 획득할 뿐 아니라 그 위치에 새로운 값을 설정(대입)할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "TX\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(df.iat[1, 0])\n",
    "print(df.iat[3, 1])\n",
    "# 60\n",
    "# TX\n",
    "\n",
    "df.iat[1, 0] = 42\n",
    "print(df.iat[1, 0])\n",
    "# 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **loc, iloc : 하나 혹은 여러 개의 요소 값을 선택, 획득, 변경**\n",
    "\n",
    "loc과 iloc은 하나의 값뿐 아니라, 범위를 지정하여 여러 개의 데이터를 선택할 수 있습니다. loc은 행 명과 열 명으로 위치를 지정하고, iloc은 행 번호와 열 번호로 위치를 지정합니다.\n",
    "\n",
    "####  **하나의 요소 값을 선택**\n",
    "\n",
    "하나의 값에 액세스할 경우 at, iat와 동일하다. 처리 속도는 앞에서 말했듯 at, iat의 쪽이 빠릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "TX\n"
     ]
    }
   ],
   "source": [
    "print(df.loc['Bob', 'age'])\n",
    "print(df.iloc[3, 1])\n",
    "# 42\n",
    "# TX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 참고할 뿐만 아니라, 그 위치에 새로운 값을 설정(대입)하는 것도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "df.loc['Bob', 'age'] = 60\n",
    "print(df.loc['Bob', 'age'])\n",
    "# 60\n",
    "\n",
    "df.iloc[1, 0] = 42\n",
    "print(df.iloc[1, 0])\n",
    "# 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **여러 개의 요소 값을 선택**\n",
    "\n",
    "여러 개의 값에 액세스할 경우는 리스트[a, b, c, ...]나 슬라이스 start:stop:step으로 데이터의 범위, 위치를 지정할 수 있다. pandas.Series 혹은 pandas.DataFrame가 반환된다.\n",
    "\n",
    "슬라이스는 보통의 슬라이스 작성법과 같다. step은 생략가능하다.\n",
    "\n",
    "슬라이스 start:stop:step으로 지정할 때, iloc으로 행 번호, 열 번호를 사용하는 경우 일반적인 슬라이스와 동일하게 stop의 한 단계 전까지이지만, loc으로 행 명, 열 명을 사용하는 경우는 stop의 값도 포함되므로 주의가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "Bob        42\n",
      "Charlie    18\n",
      "Dave       68\n",
      "Name: age, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "         age  point\n",
      "name               \n",
      "Alice     24     64\n",
      "Bob       42     92\n",
      "Charlie   18     70\n",
      "Dave      68     70\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "         age  point\n",
      "name               \n",
      "Alice     24     64\n",
      "Bob       42     92\n",
      "Charlie   18     70\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(df.loc['Bob':'Dave', 'age'])\n",
    "print(type(df.loc['Bob':'Dave', 'age']))\n",
    "# name\n",
    "# Bob        42\n",
    "# Charlie    18\n",
    "# Dave       68\n",
    "# Name: age, dtype: int64\n",
    "# <class 'pandas.core.series.Series'>\n",
    "\n",
    "print(df.loc[:'Dave', ['age', 'point']])\n",
    "print(type(df.loc[:'Dave', 'age':'point']))\n",
    "#          age  point\n",
    "# name\n",
    "# Alice     24     64\n",
    "# Bob       42     92\n",
    "# Charlie   18     70\n",
    "# Dave      68     70\n",
    "# <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "print(df.iloc[:3, [0, 2]])\n",
    "print(type(df.iloc[:3, [0, 2]]))\n",
    "#          age  point\n",
    "# name\n",
    "# Alice     24     64\n",
    "# Bob       42     92\n",
    "# Charlie   18     70\n",
    "# <class 'pandas.core.frame.DataFrame'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step을 지정하면, 홀수행 혹은 짝수행을 추출하여 획득하는 것도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "Alice      24\n",
      "Charlie    18\n",
      "Ellen      24\n",
      "Name: age, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "name\n",
      "Bob      42\n",
      "Dave     68\n",
      "Frank    30\n",
      "Name: age, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[::2, 0])\n",
    "print(type(df.iloc[::2, 0]))\n",
    "# name\n",
    "# Alice      24\n",
    "# Charlie    18\n",
    "# Ellen      24\n",
    "# Name: age, dtype: int64\n",
    "# <class 'pandas.core.series.Series'>\n",
    "\n",
    "print(df.iloc[1::2, 0])\n",
    "print(type(df.iloc[1::2, 0]))\n",
    "# name\n",
    "# Bob      42\n",
    "# Dave     68\n",
    "# Frank    30\n",
    "# Name: age, dtype: int64\n",
    "# <class 'pandas.core.series.Series'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 개의 값을 일괄로 변경하는 것도 가능합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "Bob        20\n",
      "Charlie    30\n",
      "Dave       40\n",
      "Name: age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.loc['Bob':'Dave', 'age'] = [20, 30, 40]\n",
    "print(df.loc['Bob':'Dave', 'age'])\n",
    "# name\n",
    "# Bob        20\n",
    "# Charlie    30\n",
    "# Dave       40\n",
    "# Name: age, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **행, 열을 선택**\n",
    "\n",
    "인덱스 참조 df[]로 행, 열을 선택할 수 있지만, 아래의 지정 방법에 한정됩니다.\n",
    "\n",
    "- 행의 선택 : 행 이름, 행 번호의 인덱스\n",
    "- 열의 선택 : 열 이름, 혹은 열 이름의 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age state  point\n",
      "name                     \n",
      "Bob       20    CA     92\n",
      "Charlie   30    CA     70\n",
      "Dave      40    TX     70\n",
      "Ellen     24    CA     88\n",
      "         age state  point\n",
      "name                     \n",
      "Alice     24    NY     64\n",
      "Bob       20    CA     92\n",
      "Charlie   30    CA     70\n",
      "name\n",
      "Alice      24\n",
      "Bob        20\n",
      "Charlie    30\n",
      "Dave       40\n",
      "Ellen      24\n",
      "Frank      30\n",
      "Name: age, dtype: int64\n",
      "         age  point\n",
      "name               \n",
      "Alice     24     64\n",
      "Bob       20     92\n",
      "Charlie   30     70\n",
      "Dave      40     70\n",
      "Ellen     24     88\n",
      "Frank     30     57\n"
     ]
    }
   ],
   "source": [
    "print(df['Bob':'Ellen'])\n",
    "#          age state  point\n",
    "# name\n",
    "# Bob       20    CA     92\n",
    "# Charlie   30    CA     70\n",
    "# Dave      40    TX     70\n",
    "# Ellen     24    CA     88\n",
    "\n",
    "print(df[:3])\n",
    "#          age state  point\n",
    "# name\n",
    "# Alice     24    NY     64\n",
    "# Bob       20    CA     92\n",
    "# Charlie   30    CA     70\n",
    "\n",
    "print(df['age'])\n",
    "# name\n",
    "# Alice      24\n",
    "# Bob        20\n",
    "# Charlie    30\n",
    "# Dave       40\n",
    "# Ellen      24\n",
    "# Frank      30\n",
    "# Name: age, dtype: int64\n",
    "\n",
    "print(df[['age', 'point']])\n",
    "#          age  point\n",
    "# name\n",
    "# Alice     24     64\n",
    "# Bob       20     92\n",
    "# Charlie   30     70\n",
    "# Dave      40     70\n",
    "# Ellen     24     88\n",
    "# Frank     30     57​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loc, iloc으로 행, 열을 선택할 경우는 인덱스 참고 df[]보다 유연하게 지정할 수 있습니다.\n",
    "\n",
    "loc, iloc에서 열의 지정을 생략하면 열 참조가 된다. 인덱스 참조에서는 할 수 없는 행 이름, 열 번호 단독 지정이나 리스트에 의한 지정도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age      20\n",
      "state    CA\n",
      "point    92\n",
      "Name: Bob, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n",
      "       age state  point\n",
      "name                   \n",
      "Bob     20    CA     92\n",
      "Ellen   24    CA     88\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(df.loc['Bob'])\n",
    "print(type(df.loc['Bob']))\n",
    "# age      20\n",
    "# state    CA\n",
    "# point    92\n",
    "# Name: Bob, dtype: object\n",
    "# <class 'pandas.core.series.Series'>\n",
    "\n",
    "print(df.iloc[[1, 4]])\n",
    "print(type(df.iloc[[1, 4]]))\n",
    "#        age state  point\n",
    "# name\n",
    "# Bob     20    CA     92\n",
    "# Ellen   24    CA     88\n",
    "# <class 'pandas.core.frame.DataFrame'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loc, iloc으로 행의 지정을 : (전체의 슬라이스)로 하면 열을 참조할 수 있습니다. \n",
    "\n",
    "인덱스 참조에서는 할 수 없는 슬라이스에 의한 지정도 가능하다. iloc으로 열 번호를 사용하는 것도 가능합니다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age state  point\n",
      "name                     \n",
      "Alice     24    NY     64\n",
      "Bob       20    CA     92\n",
      "Charlie   30    CA     70\n",
      "Dave      40    TX     70\n",
      "Ellen     24    CA     88\n",
      "Frank     30    NY     57\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "         age  point\n",
      "name               \n",
      "Alice     24     64\n",
      "Bob       20     92\n",
      "Charlie   30     70\n",
      "Dave      40     70\n",
      "Ellen     24     88\n",
      "Frank     30     57\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[:, 'age':'point'])\n",
    "print(type(df.loc[:, 'age':'point']))\n",
    "#          age state  point\n",
    "# name\n",
    "# Alice     24    NY     64\n",
    "# Bob       20    CA     92\n",
    "# Charlie   30    CA     70\n",
    "# Dave      40    TX     70\n",
    "# Ellen     24    CA     88\n",
    "# Frank     30    NY     57\n",
    "# <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "print(df.iloc[:, [0, 2]])\n",
    "print(type(df.iloc[:, [0, 2]]))\n",
    "#          age  point\n",
    "# name\n",
    "# Alice     24     64\n",
    "# Bob       20     92\n",
    "# Charlie   30     70\n",
    "# Dave      40     70\n",
    "# Ellen     24     88\n",
    "# Frank     30     57\n",
    "# <class 'pandas.core.frame.DataFrame'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행 이름-행 번호, 열 이름-열 번호를 하나로 지정하여 하나의 행-하나의 열을 선택하는 경우는 pandas.Series가 반환되지만,\n",
    "\n",
    " 동일한 하나의 행 - 하나의 열을 선택하는 경우에도 슬라이스나 리스트로 지정한 경우는 pandas.DataFrame이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age      20\n",
      "state    CA\n",
      "point    92\n",
      "Name: Bob, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n",
      "      age state  point\n",
      "name                  \n",
      "Bob    20    CA     92\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "      age state  point\n",
      "name                  \n",
      "Bob    20    CA     92\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(df.loc['Bob'])\n",
    "print(type(df.loc['Bob']))\n",
    "# age      20\n",
    "# state    CA\n",
    "# point    92\n",
    "# Name: Bob, dtype: object\n",
    "# <class 'pandas.core.series.Series'>\n",
    "\n",
    "print(df.loc['Bob':'Bob'])\n",
    "print(type(df.loc['Bob':'Bob']))\n",
    "#       age state  point\n",
    "# name\n",
    "# Bob    20    CA     92\n",
    "# <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "print(df.loc[['Bob']])\n",
    "print(type(df.loc[['Bob']]))\n",
    "#       age state  point\n",
    "# name\n",
    "# Bob    20    CA     92\n",
    "# <class 'pandas.core.frame.DataFrame'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "Alice      NY\n",
      "Bob        CA\n",
      "Charlie    CA\n",
      "Dave       TX\n",
      "Ellen      CA\n",
      "Frank      NY\n",
      "Name: state, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n",
      "        state\n",
      "name         \n",
      "Alice      NY\n",
      "Bob        CA\n",
      "Charlie    CA\n",
      "Dave       TX\n",
      "Ellen      CA\n",
      "Frank      NY\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "        state\n",
      "name         \n",
      "Alice      NY\n",
      "Bob        CA\n",
      "Charlie    CA\n",
      "Dave       TX\n",
      "Ellen      CA\n",
      "Frank      NY\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[:, 1])\n",
    "print(type(df.iloc[:, 1]))\n",
    "# name\n",
    "# Alice      NY\n",
    "# Bob        CA\n",
    "# Charlie    CA\n",
    "# Dave       TX\n",
    "# Ellen      CA\n",
    "# Frank      NY\n",
    "# Name: state, dtype: object\n",
    "# <class 'pandas.core.series.Series'>\n",
    "\n",
    "print(df.iloc[:, 1:2])\n",
    "print(type(df.iloc[:, 1:2]))\n",
    "#         state\n",
    "# name\n",
    "# Alice      NY\n",
    "# Bob        CA\n",
    "# Charlie    CA\n",
    "# Dave       TX\n",
    "# Ellen      CA\n",
    "# Frank      NY\n",
    "# <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "print(df.iloc[:, [1]])\n",
    "print(type(df.iloc[:, [1]]))\n",
    "#         state\n",
    "# name\n",
    "# Alice      NY\n",
    "# Bob        CA\n",
    "# Charlie    CA\n",
    "# Dave       TX\n",
    "# Ellen      CA\n",
    "# Frank      NY\n",
    "# <class 'pandas.core.frame.DataFrame'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특히, 행을 pandas.Series로 선택하면 암묵적 형변환이 이뤄질 가능성이 있으므로 주의할 필요가 있습니다.\n",
    "\n",
    "## **행 명과 열 명이 중복된 값을 가지고 있는 경우**\n",
    "\n",
    "행 명(행 라벨) index, 열 명(열 라벨) columns에 중복된 값이 포함되어 있어도 에러가 발생하지 않습니다.\n",
    "\n",
    "중복된 값을 가진 열을 index에 지정한 경우 다음과 같은 예가 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './sample_pandas_normal.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\seonghun.han\\Desktop\\K-Soft\\Day9\\9) python-pandas-data-analysis.zip (Unzipped Files)\\python-pandas-data-analysis.ipynb 셀 71\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/seonghun.han/Desktop/K-Soft/Day9/9%29%20python-pandas-data-analysis.zip%20%28Unzipped%20Files%29/python-pandas-data-analysis.ipynb#ch0000070?line=0'>1</a>\u001b[0m df_state \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m./sample_pandas_normal.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, index_col\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seonghun.han/Desktop/K-Soft/Day9/9%29%20python-pandas-data-analysis.zip%20%28Unzipped%20Files%29/python-pandas-data-analysis.ipynb#ch0000070?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(df_state)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seonghun.han/Desktop/K-Soft/Day9/9%29%20python-pandas-data-analysis.zip%20%28Unzipped%20Files%29/python-pandas-data-analysis.ipynb#ch0000070?line=2'>3</a>\u001b[0m \u001b[39m#           name  age  point\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seonghun.han/Desktop/K-Soft/Day9/9%29%20python-pandas-data-analysis.zip%20%28Unzipped%20Files%29/python-pandas-data-analysis.ipynb#ch0000070?line=3'>4</a>\u001b[0m \u001b[39m# state\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seonghun.han/Desktop/K-Soft/Day9/9%29%20python-pandas-data-analysis.zip%20%28Unzipped%20Files%29/python-pandas-data-analysis.ipynb#ch0000070?line=4'>5</a>\u001b[0m \u001b[39m# NY       Alice   24     64\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seonghun.han/Desktop/K-Soft/Day9/9%29%20python-pandas-data-analysis.zip%20%28Unzipped%20Files%29/python-pandas-data-analysis.ipynb#ch0000070?line=8'>9</a>\u001b[0m \u001b[39m# CA       Ellen   24     88\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/seonghun.han/Desktop/K-Soft/Day9/9%29%20python-pandas-data-analysis.zip%20%28Unzipped%20Files%29/python-pandas-data-analysis.ipynb#ch0000070?line=9'>10</a>\u001b[0m \u001b[39m# NY       Frank   30     57\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\seonghun.han\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\seonghun.han\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\seonghun.han\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\seonghun.han\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\seonghun.han\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m     f,\n\u001b[0;32m   1220\u001b[0m     mode,\n\u001b[0;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1227\u001b[0m )\n\u001b[0;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\seonghun.han\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './sample_pandas_normal.csv'"
     ]
    }
   ],
   "source": [
    "df_state = pd.read_csv('./sample_pandas_normal.csv', index_col=2)\n",
    "print(df_state)\n",
    "#           name  age  point\n",
    "# state\n",
    "# NY       Alice   24     64\n",
    "# CA         Bob   42     92\n",
    "# CA     Charlie   18     70\n",
    "# TX        Dave   68     70\n",
    "# CA       Ellen   24     88\n",
    "# NY       Frank   30     57\n",
    "\n",
    "print(df_state.index.values)\n",
    "# ['NY' 'CA' 'CA' 'TX' 'CA' 'NY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "at으로 중복된 열 이름을 지정하면, numpy.ndarray로 여러 개의 값이 반환되어 옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_state.at['NY', 'age'])\n",
    "print(type(df_state.at['NY', 'age']))\n",
    "# [24 30]\n",
    "# <class 'numpy.ndarray'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loc으로 중복된 행 명을 지정하면, pandas.DataFrame 혹은 pandas.Series가 반환됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_state.loc['NY', 'age'])\n",
    "print(type(df_state.loc['NY', 'age']))\n",
    "# state\n",
    "# NY    24\n",
    "# NY    30\n",
    "# Name: age, dtype: int64\n",
    "# <class 'pandas.core.series.Series'>\n",
    "\n",
    "print(df_state.loc['NY', ['age', 'point']])\n",
    "print(type(df_state.loc['NY', ['age', 'point']]))\n",
    "#        age  point\n",
    "# state\n",
    "# NY      24     64\n",
    "# NY      30     57\n",
    "# <class 'pandas.core.frame.DataFrame'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iat이나 iloc에서 행 번호으로 지정하는 경우는 행 번호가 중복되어 있어도 특히 문제가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_state.iat[0, 1])\n",
    "# 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "혼란의 근원이되므로, 강력한 이유가 없다면 지정할 때, 행 이름-열 이름은 임의의 값으로 하는 편이 좋습니다.\n",
    "\n",
    "행 이름 - 열 이름이 임의의 값으로 되어 있는지 아닌지(중복되는지 아닌지)는 index.is_unique, columns.is_unique로 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_state.index.is_unique)\n",
    "# False\n",
    "\n",
    "print(df_state.columns.is_unique)\n",
    "# True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **번호와 라벨로 위치를 지정하기**\n",
    "\n",
    "행 번호와 열 라벨과 같이 번호와 라벨의 조합으로 위치를 지정하고 싶은 경우, at 혹은 loc과 index나 columns를 사용하는 방법이 있습니다.\n",
    "\n",
    "index나 columns로 행 번호 혹은 열 변호로부터 그 행 라벨, 열 라벨을 획득할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)\n",
    "#          age state  point\n",
    "# name\n",
    "# Alice     24    NY     64\n",
    "# Bob       20    CA     92\n",
    "# Charlie   30    CA     70\n",
    "# Dave      40    TX     70\n",
    "# Ellen     24    CA     88\n",
    "# Frank     30    NY     57\n",
    "\n",
    "print(df.index[2])\n",
    "# Charlie\n",
    "\n",
    "print(df.columns[1])\n",
    "# state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것과 at 혹은 loc를 사용하여, 번호와 라벨의 조합으로 위치를 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.at[df.index[2], 'age'])\n",
    "# 30\n",
    "\n",
    "print(df.loc[['Alice', 'Dave'], df.columns[1]])\n",
    "# name\n",
    "# Alice    NY\n",
    "# Dave     TX\n",
    "# Name: state, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 서술했듯이, 슬라이스로 지정할 때, loc으로 행 라벨, 열 라벨을 사용하는 경우는 stop까지 포함되지만, iloc에서 행 번호, 열 번호를 사용하는 경우는 stop의 하나 앞까지가 됩니다. stop의 값을 번호로부터 라벨으로 변환하는 경우 index[n-1]로 할 필요가 있으므로 주의하자.\n",
    "\n",
    "아래와 같이 []나 loc, iloc을 반복해 작성할 수 있지만, 이것은 chained indexing이라는 것으로 SettingWithCopyWarning이라는 경고의 원인이 됩니다.\n",
    "\n",
    "또한, 다음에 설명하는 것과 같이, 하나의 행을 선택할 경우는 암묵적 형변환이 일어나는 경우가 있습니다. 앞에서 표시된 index나 column을 사용하여 하나의 at이나 loc으로 묶어서 사용하는 편이 좋습니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['age'][2])\n",
    "# 30\n",
    "\n",
    "print(df.age[2])\n",
    "# 30\n",
    "\n",
    "print(df.loc[['Alice', 'Dave']].iloc[:, 1])\n",
    "# name\n",
    "# Alice    NY\n",
    "# Dave     TX\n",
    "# Name: state, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **행을 pandas.Series로 선택할 때의 묵시적 형변환**\n",
    "\n",
    "loc이나 iloc으로 하나의 행을 pandas.Series로 선택해 획득할 경우, 데이터형 dtype으로 통일되므로, 원래의 pandas.DataFrame 행 데이터 형이 달라지는 묵시적 형 변환이 일어납니다.\n",
    "\n",
    "정수 int의 열와 부동 소수점 수 float을 가진 pandas.DataFrame을 통해 살펴봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mix = pd.DataFrame({'col_int': [0, 1, 2], 'col_float': [0.1, 0.2, 0.3]}, index=['A', 'B', 'C'])\n",
    "print(df_mix)\n",
    "#    col_int  col_float\n",
    "# A        0        0.1\n",
    "# B        1        0.2\n",
    "# C        2        0.3\n",
    "\n",
    "print(df_mix.dtypes)\n",
    "# col_int        int64\n",
    "# col_float    float64\n",
    "# dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loc이나 iloc으로 1행을 획득하면, float의 pandas.Series가 됩니다. int의 열에 있던 데이터는 float로 변환된다는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_mix.loc['B'])\n",
    "# col_int      1.0\n",
    "# col_float    0.2\n",
    "# Name: B, dtype: float64\n",
    "\n",
    "print(type(df_mix.loc['B']))\n",
    "# <class 'pandas.core.series.Series'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 []을 연속해서 작성하면, float로 변환된 pandas.Series의 요소가 획득되게 됩니다.. 원래 데이터형과 다른 데이터형으로 변환된 데이터 값을 얻게 되므로 주의해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_mix.loc['B']['col_int'])\n",
    "# 1.0\n",
    "\n",
    "print(type(df_mix.loc['B']['col_int']))\n",
    "# <class 'numpy.float64'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 이러한 현상을 피하려면, at이나 iat을 사용하는 편이 좋습니다. at이나 iat이면 원래 데이터형 그대로 값을 취득할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_mix.at['B', 'col_int'])\n",
    "# 1\n",
    "\n",
    "print(type(df_mix.at['B', 'col_int']))\n",
    "# <class 'numpy.int64'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loc이나 iloc으로 1개의 리스트로 지정하는 경우, pandas.Series가 아닌 하나의 pandas.DataFrame행이 된다. 당연하지만, 이 경우는 원래 데이터형 dtype이 유지됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_mix.loc[['B']])\n",
    "#    col_int  col_float\n",
    "# B        1        0.2\n",
    "\n",
    "print(type(df_mix.loc[['B']]))\n",
    "# <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "print(df_mix.loc[['B']].dtypes)\n",
    "# col_int        int64\n",
    "# col_float    float64\n",
    "# dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>996.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>975.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  new_cases  new_deaths  new_tests\n",
       "0    2019-12-31        0.0         0.0        NaN\n",
       "1    2020-01-01        0.0         0.0        NaN\n",
       "2    2020-01-02        0.0         0.0        NaN\n",
       "3    2020-01-03        0.0         0.0        NaN\n",
       "4    2020-01-04        0.0         0.0        NaN\n",
       "..          ...        ...         ...        ...\n",
       "243  2020-08-30     1444.0         1.0    53541.0\n",
       "244  2020-08-31     1365.0         4.0    42583.0\n",
       "245  2020-09-01      996.0         6.0    54395.0\n",
       "246  2020-09-02      975.0         8.0        NaN\n",
       "247  2020-09-03     1326.0         6.0        NaN\n",
       "\n",
       "[248 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.loc[243]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각의 행들은 `Series` 형태로 구성되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(covid_df.loc[243])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `.head` 와 `.tail`함수는 처음, 마지막 행의 일부를 반환하는데, 그 개수는 ()안에 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`new_tests` 의 head부분을 보면 NaN으로 구성된 값들이 존재한다는 것을 알 수 있습니다. <br>\n",
    "이는 0의 값을 가지고 있는 `new_cases`와 `new_death`와는 다르게 값이 누락되어 있는 상태를 의미합니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.at[0, 'new_tests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(covid_df.at[0, 'new_tests'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`0`과 `NaN`의 차이는 미묘하지만 매우 중요합니다.<br>\n",
    "이탈리아는 2020년 4월19일부터 일간 검사자를 보고하기 시작했기 때문에, 이 dataset에서는 일부 일자에 대해서는 검사자가 보고되지 않았습니다.<br>\n",
    "\n",
    "우리는 `first_vaild_index` 함수를 통해서 처음으로 결측치가 아닌 값이 언제 나오는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.new_tests.first_valid_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NaN`에서 측정값으로 바뀌기 전의 몇몇 행들을 살펴보겠습니다. 앞서 배운 것과 같이, `loc` 함수를 사용해서 행 데이터에 접근할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.loc[108:113]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample` 함수는 데이터 프레임에서 랜덤으로 일부 행들을 추출하여 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤으로 추출한 샘플 데이터 안에서도, 각각의 행들의 원래 인덱스가 보존된다는 것을 확인할 수 있습니다.<br>\n",
    "이는 데이터 프레임의 유용한 특성 중 하나입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서 사용한 함수와 특성을 정리하면 다음과 같습니다.\n",
    "\n",
    "- `.copy()` - 데이터 프레임의 깊은 복사\n",
    "- `.loc[]` - 데이터프레임 행 단위의 데이터 접근\n",
    "- `head`, `tail`, `sample` - 데이터 프레임에서 앞, 두, 랜덤의 샘플데이터를 다루기\n",
    "- `first_valid_index` - 처음으로 유효값이 나오는 인덱스 찾기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 프레임의 데이터 분석하기\n",
    "\n",
    "아래 질문에 대한 답을 생각해보십시오.<br>\n",
    "\n",
    "**Q: 이탈리아에서 총 보고된 신규 확진자와 사망자는 몇명인가?**\n",
    "\n",
    "Numpy와 비슷하게 Pandas는 `sum` 함수를 사용하여 합을 구할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_cases = covid_df.new_cases.sum()\n",
    "total_deaths = covid_df.new_deaths.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of reported cases is 271515 and the number of reported deaths is 35497.\n"
     ]
    }
   ],
   "source": [
    "print('The number of reported cases is {} and the number of reported deaths is {}.'.format(int(total_cases), int(total_deaths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: 전체 사망률은 어떻게 되는가?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_rate = covid_df.new_deaths.sum() / covid_df.new_cases.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The overall reported death rate in Italy is {:.2f} %.\".format(death_rate*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: 전체 검사자는 몇명 인가? 935310명의 검사자가 보고되기 전에 존재했다.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tests = 935310\n",
    "total_tests = initial_tests + covid_df.new_tests.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: 검사 중 양성 판정이 나온 비율은 얼마나 되는가?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_rate = total_cases / total_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:.2f}% of tests in Italy led to a positive diagnosis.'.format(positive_rate*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 쿼리와 데이터 정렬\n",
    "\n",
    "1000건이 넘는 보고가 존재한 날짜의 데이터만 보고싶다고 생각해보십시오.<br>\n",
    "boolean 표현을 이용해 이를 만족하는 행의 데이터를 추출하면 됩니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_new_cases = covid_df.new_cases > 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_new_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 부울 표현식은 인덱스별로 `True` 와 `False`로 값이 존재하는 결과를 반환합니다.<br>\n",
    "이를 이용해서 `True`값을 가지는 인덱스에 대한 데이터만 추출하는 것도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df[high_new_cases]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 인덱스 칸안에 boolean 표현식을 넣어서 한줄로 간결하게 표현할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cases_df = covid_df[covid_df.new_cases > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cases_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 데이터 프레임은 72개의 행을 가지고 있습니다. <br>\n",
    "데이터가 많아서 위아래 몇개의 데이터만 표현됩니다. <br>\n",
    "전체 데이터를 보고 싶을 때는 아래와 같이 데이터 프레임에 접근하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "with pd.option_context('display.max_rows', 100):\n",
    "    display(covid_df[covid_df.new_cases > 1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 개의 열에 한번에 접근하고 데이터를 처리하기 위해 보다 복잡한 쿼리문을 만드는 것도 가능합니다. <br>\n",
    "예를 들어 전체 양성비율보다 일별 양성비율이 높은 날의 데이터만을 추출하는 것도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_ratio_df = covid_df[covid_df.new_cases / covid_df.new_tests > positive_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_ratio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 개의 열을 처리하게 되면 새로운 Series 데이터가 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.new_cases / covid_df.new_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 Series 데이터를 데이터프레임에 추가할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['positive_rate'] = covid_df.new_cases / covid_df.new_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 코로나 검사는 몇일이 소요되기 때문에, 양성 결과 비율을 날짜에 그대로 대입하는 것은 부적절한 경우가 될 수도 있습니다.<br>\n",
    "이러한 부정확한 내용은 전체 데이터를 분석함에 있어서 부적절하기 때문에 해당 열을 제거하도록 하겠습니다.<br>\n",
    "\n",
    "\n",
    "`positive_rate` 열을 판다스의 `drop`함수를 이용해서 제거해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.drop(columns=['positive_rate'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inplace` 파라미터의 목적이 이해가 되나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 열 데이터를 이용해서 행 정렬\n",
    "\n",
    "`sort_values`를 이용하면 행 데이터를 특정 열을 기준으로 정렬할 수 있습니다. <br>\n",
    "신규확진자가 많은 순서대로 데이터를 정렬하기 위해 `new_cases`를 기준으로 내림차순 정렬을 해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.sort_values('new_cases', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일별 발생 건수가 3월 마지막 2주 동안 가장 많았던 것으로 보입니다.  \n",
    "이를 사망자가 가장 많았던 날과 비교해보겠습니다.\n",
    "<!--It looks like the last two weeks of March had the highest number of daily cases. Let's compare this to the days where the highest number of deaths were recorded.-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.sort_values('new_deaths', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일별 사망자는 일별 확진자가 최고치를 기록한 몇일후부터 최고치가 기록되는 것을 확인할 수 있습니다.\n",
    "\n",
    "최소 확진자를 처음으로 보기위해서 오름차순으로 정렬을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.sort_values('new_cases').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 적은 수의 값이 `-148`로 음수가 기록되어 있다는 것을 확인할 수 있습니다.<br>\n",
    "이는 실제로 발생할 수 없는 값으로 잘못된 기록일 것이므로, 이상치가 나온 2020년 6월 20일 이전의 자료들을 확인해보도록 하겠습니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.loc[169:175]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 값이 잘못되었다는 것을 확인할 수 있었습니다.<br>\n",
    "이와 같은 이상 데이터에 대해서는 다음과 같은 몇가지 처리방법들로 해당 값을 대체해야 합니다. <br>\n",
    "<br>\n",
    "1. `0`으로 대체\n",
    "2. 전체에 대한 평균으로 대체\n",
    "3. 이전날과 다음날에 대한 평균으로 대체\n",
    "4. 해당 열 전체를 삭제\n",
    "<br>\n",
    "어떠한 방법론을 선택할지는 데이터와 문제의 문맥이 중요합니다. <br>\n",
    "\n",
    "여기서는 날짜 단위의 데이터를 다루고 있기 때문에 3번째 방법론을 사용하기로 합니다.<br>\n",
    "\n",
    "`at` 함수를 사용해서 특정 값을 바꿀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.at[172, 'new_cases'] = (covid_df.at[171, 'new_cases'] + covid_df.at[173, 'new_cases'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지의 함수를 요약한다면 다음과 같습니다:\n",
    "\n",
    "- `covid_df.new_cases.sum()` - 특정 열 또는 특정 행 Series 내의 합을 구함\n",
    "- `covid_df[covid_df.new_cases > 1000]` - 특정 조건을 만족하는 행 데이터만 추출한다.\n",
    "- `df['pos_rate'] = df.new_cases/df.new_tests` - 존재하는 열의 데이터를 이용해서 새로운 열을 만들어 낸다.\n",
    "- `covid_df.drop('positive_rate')` -한개 또는 여러개의 열을 제거한다.\n",
    "- `sort_values` - 열 값을 이용해서 데이터를 정렬한다.\n",
    "- `covid_df.at[172, 'new_cases'] = ...` - 특정 값으로 데이터를 대체한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시간의 활용\n",
    "\n",
    "이전까지는 전반적인 데이터들의 개수를 다루는 작업을 해보았습니다.<br>\n",
    "이러한 데이터들을 날짜, 시간 기준으로 접근할 수 있다면 더욱 유용할 것입니다.<br>\n",
    "`date` 열은 데이터의 시간 정보를 담고 있는 특성입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 data 데이터의 형식은 `object`로 되어 있습니다. <br>\n",
    "따라서 Pandas 데이터 프레임은 해당 열이 어떤 데이터인지 정확하게 이해하고 있지 못한 상태이며,   \n",
    "data 데이터를 시계열 특성에 맞게 처리하기 위해서 `pd.to_datetime`함수를 이용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['date'] = pd.to_datetime(covid_df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`datetime64`라는  데이터 타입으로 변환된 것을 확인할 수 있습니다.<br>\n",
    "이제 데이터 프레임에 존재하는 데이터들은 시간 단위로 접근하여 추출하고 수정할 수 있게 되었습니다.<br>\n",
    "시계열 데이터를 시간단위로 사용하기 위해서는 `DatetimeIndex` 클래스를 사용합니다 ([view docs](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DatetimeIndex.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['year'] = pd.DatetimeIndex(covid_df.date).year\n",
    "covid_df['month'] = pd.DatetimeIndex(covid_df.date).month\n",
    "covid_df['day'] = pd.DatetimeIndex(covid_df.date).day\n",
    "covid_df['weekday'] = pd.DatetimeIndex(covid_df.date).weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5월의 전반적인 데이터 프레임을 확인해보도록 하겠습니다.<br>\n",
    "열을 찾는 인덱스를 5월로 주고 접근하고자 하는 열을 선택하면 됩니다.<br>\n",
    "그리고 `sum` 함수를 사용해서 각 열들의 합계를 구해보겠습니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5월의 행을 구하는 쿼리\n",
    "covid_df_may = covid_df[covid_df.month == 5]\n",
    "\n",
    "# 처리하고자 하는 열에 접근\n",
    "covid_df_may_metrics = covid_df_may[['new_cases', 'new_deaths', 'new_tests']]\n",
    "\n",
    "# 열에 대한 합 구하기\n",
    "covid_may_totals = covid_df_may_metrics.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_may_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(covid_may_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 연산들을 한줄의 코드로 축약할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df[covid_df.month == 5][['new_cases', 'new_deaths', 'new_tests']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또다른 예시를 확인해보겠습니다. <br>\n",
    "일요일에 보고된 내용들이 다른 날에 보고된 평균보다 높은지 확인해보고, 이번에는 `.mean`함수를 사용해서 열들의 평균정보를 구해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 평균\n",
    "covid_df.new_cases.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일요일의 평균\n",
    "covid_df[covid_df.weekday == 6].new_cases.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 묶어내기와 분리하기\n",
    "\n",
    "이번에는, 데이터를 월데이터가 없이 일단위로만 묶어서 데이터를 정렬한 새로운 데이터프레임을 만들어 보도록 하겠습니다.<br>\n",
    "`groupby`함수를 사용해서 각 달의 데이터를 추출하고 `sum`함수를 사용해서 열 데이터를 합칩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'month'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\seonghun.han\\Desktop\\K-Soft\\Day9\\9) python-pandas-data-analysis.zip (Unzipped Files)\\python-pandas-data-analysis.ipynb 셀 177\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/seonghun.han/Desktop/K-Soft/Day9/9%29%20python-pandas-data-analysis.zip%20%28Unzipped%20Files%29/python-pandas-data-analysis.ipynb#ch0000176?line=0'>1</a>\u001b[0m covid_month_df \u001b[39m=\u001b[39m covid_df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mmonth\u001b[39;49m\u001b[39m'\u001b[39;49m)[[\u001b[39m'\u001b[39m\u001b[39mnew_cases\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnew_deaths\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnew_tests\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39msum()\n",
      "File \u001b[1;32mc:\\Users\\seonghun.han\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py:7718\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7713\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7715\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   7716\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7717\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7718\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   7719\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   7720\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   7721\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   7722\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   7723\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   7724\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   7725\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   7726\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7727\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   7728\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   7729\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\seonghun.han\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    883\u001b[0m         obj,\n\u001b[0;32m    884\u001b[0m         keys,\n\u001b[0;32m    885\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    886\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    887\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    888\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    889\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[0;32m    890\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    894\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\seonghun.han\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    880\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    883\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'month'"
     ]
    }
   ],
   "source": [
    "covid_month_df = covid_df.groupby('month')[['new_cases', 'new_deaths', 'new_tests']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_month_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`groupby`와 인덱스 접근을 활용해서 데이터 프레임을 특정 조건에 맞게 그룹으로 묶어서 사용할 수 있습니다.<br>\n",
    "이러한 묶어내는 작업은 판다스 데이터 프레임의 강력한 기능이고 큰 장점 중 하나입니다.<br>\n",
    "\n",
    "합을 기준으로 그룹을 만드는 것 대신에 평균을 기준으로 그룹을 만들수도 있습니다.<br>\n",
    "데이터들의 월별 평균을 구해서 그룹을 만들어보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_month_mean_df = covid_df.groupby('month')[['new_cases', 'new_deaths', 'new_tests']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_month_mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "존재하는 데이터들을 가지고 만들어내는 그룹을 만드는 것 대신에, 누적 데이터를 만들어내는 것도 가능합니다.<br>\n",
    "\n",
    "`cumsum`함수 를 사용해서 Series데이터의 누적합을 구할 수 있습니다.<br>\n",
    ">`cumsum`: 주어진 축에 따라 누적되는 원소들의 누적 합을 계산하는 함수\n",
    "\n",
    "\n",
    "다음 세가지 열을 만들어 보도록 하겠습니다.: `total_cases`, `total_deaths`, `total_tests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['total_cases'] = covid_df.new_cases.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['total_deaths'] = covid_df.new_deaths.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['total_tests'] = covid_df.new_tests.cumsum() + initial_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`total_test`의 `NaN` 값은 영향력이 없다는 것을 기억하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다양한 데이터들을 합치기\n",
    "\n",
    "현재 데이터만으로는 알 수 없는 정보를 얻고 싶을 때는 다른 데이터를 가져와 합칠 수 있습니다.<br>\n",
    "이탈리아를 포함한 여러 나라의 데이터를 가지고 있는 `location.csv`를 다운로드 받아서 사용해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('locations.csv', <http.client.HTTPMessage at 0x23a3cfad160>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlretrieve('https://gist.githubusercontent.com/aakashns/8684589ef4f266116cdce023377fc9c8/raw/99ce3826b2a9d1e6d0bde7e9e559fc8b6e9ac88b/locations.csv', \n",
    "            'locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df = pd.read_csv('locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>continent</th>\n",
       "      <th>population</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>gdp_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.892834e+07</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1803.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2.877800e+06</td>\n",
       "      <td>78.57</td>\n",
       "      <td>2.890</td>\n",
       "      <td>11803.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Africa</td>\n",
       "      <td>4.385104e+07</td>\n",
       "      <td>76.88</td>\n",
       "      <td>1.900</td>\n",
       "      <td>13913.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>Europe</td>\n",
       "      <td>7.726500e+04</td>\n",
       "      <td>83.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Africa</td>\n",
       "      <td>3.286627e+07</td>\n",
       "      <td>61.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5819.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>Asia</td>\n",
       "      <td>2.982597e+07</td>\n",
       "      <td>66.12</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1479.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>Africa</td>\n",
       "      <td>1.838396e+07</td>\n",
       "      <td>63.89</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3689.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Africa</td>\n",
       "      <td>1.486293e+07</td>\n",
       "      <td>61.49</td>\n",
       "      <td>1.700</td>\n",
       "      <td>1899.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>World</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.794799e+09</td>\n",
       "      <td>72.58</td>\n",
       "      <td>2.705</td>\n",
       "      <td>15469.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>International</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          location continent    population  life_expectancy  \\\n",
       "0      Afghanistan      Asia  3.892834e+07            64.83   \n",
       "1          Albania    Europe  2.877800e+06            78.57   \n",
       "2          Algeria    Africa  4.385104e+07            76.88   \n",
       "3          Andorra    Europe  7.726500e+04            83.73   \n",
       "4           Angola    Africa  3.286627e+07            61.15   \n",
       "..             ...       ...           ...              ...   \n",
       "207          Yemen      Asia  2.982597e+07            66.12   \n",
       "208         Zambia    Africa  1.838396e+07            63.89   \n",
       "209       Zimbabwe    Africa  1.486293e+07            61.49   \n",
       "210          World       NaN  7.794799e+09            72.58   \n",
       "211  International       NaN           NaN              NaN   \n",
       "\n",
       "     hospital_beds_per_thousand  gdp_per_capita  \n",
       "0                         0.500        1803.987  \n",
       "1                         2.890       11803.431  \n",
       "2                         1.900       13913.839  \n",
       "3                           NaN             NaN  \n",
       "4                           NaN        5819.495  \n",
       "..                          ...             ...  \n",
       "207                       0.700        1479.147  \n",
       "208                       2.000        3689.251  \n",
       "209                       1.700        1899.775  \n",
       "210                       2.705       15469.207  \n",
       "211                         NaN             NaN  \n",
       "\n",
       "[212 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>continent</th>\n",
       "      <th>population</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>gdp_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60461828.0</td>\n",
       "      <td>83.51</td>\n",
       "      <td>3.18</td>\n",
       "      <td>35220.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location continent  population  life_expectancy  \\\n",
       "97    Italy    Europe  60461828.0            83.51   \n",
       "\n",
       "    hospital_beds_per_thousand  gdp_per_capita  \n",
       "97                        3.18       35220.084  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_df[locations_df.location == \"Italy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "서로 다른 두 데이터프레임을 합칠 수 있습니다.<br>\n",
    "그러나 합치기 위해서는 하나 이상의 공통된 열을 가지고 있어야 합니다. <br>\n",
    "따라서, `locataion`이라는 열을 추가하여 `Italy`로 모든 값을 채운 후 데이터를 합쳐보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['location'] = \"Italy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_tests</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53541.0</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42583.0</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>996.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54395.0</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>975.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  new_cases  new_deaths  new_tests location\n",
       "0    2019-12-31        0.0         0.0        NaN    Italy\n",
       "1    2020-01-01        0.0         0.0        NaN    Italy\n",
       "2    2020-01-02        0.0         0.0        NaN    Italy\n",
       "3    2020-01-03        0.0         0.0        NaN    Italy\n",
       "4    2020-01-04        0.0         0.0        NaN    Italy\n",
       "..          ...        ...         ...        ...      ...\n",
       "243  2020-08-30     1444.0         1.0    53541.0    Italy\n",
       "244  2020-08-31     1365.0         4.0    42583.0    Italy\n",
       "245  2020-09-01      996.0         6.0    54395.0    Italy\n",
       "246  2020-09-02      975.0         8.0        NaN    Italy\n",
       "247  2020-09-03     1326.0         6.0        NaN    Italy\n",
       "\n",
       "[248 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 우리는 `merge`함수를 사용해서 `locataion_df`를 `covid_df`로 합칠 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = covid_df.merge(locations_df, on=\"location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_tests</th>\n",
       "      <th>location</th>\n",
       "      <th>continent</th>\n",
       "      <th>population</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>gdp_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60461828.0</td>\n",
       "      <td>83.51</td>\n",
       "      <td>3.18</td>\n",
       "      <td>35220.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60461828.0</td>\n",
       "      <td>83.51</td>\n",
       "      <td>3.18</td>\n",
       "      <td>35220.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60461828.0</td>\n",
       "      <td>83.51</td>\n",
       "      <td>3.18</td>\n",
       "      <td>35220.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60461828.0</td>\n",
       "      <td>83.51</td>\n",
       "      <td>3.18</td>\n",
       "      <td>35220.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60461828.0</td>\n",
       "      <td>83.51</td>\n",
       "      <td>3.18</td>\n",
       "      <td>35220.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53541.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60461828.0</td>\n",
       "      <td>83.51</td>\n",
       "      <td>3.18</td>\n",
       "      <td>35220.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42583.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60461828.0</td>\n",
       "      <td>83.51</td>\n",
       "      <td>3.18</td>\n",
       "      <td>35220.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>996.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54395.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60461828.0</td>\n",
       "      <td>83.51</td>\n",
       "      <td>3.18</td>\n",
       "      <td>35220.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>975.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60461828.0</td>\n",
       "      <td>83.51</td>\n",
       "      <td>3.18</td>\n",
       "      <td>35220.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60461828.0</td>\n",
       "      <td>83.51</td>\n",
       "      <td>3.18</td>\n",
       "      <td>35220.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  new_cases  new_deaths  new_tests location continent  \\\n",
       "0    2019-12-31        0.0         0.0        NaN    Italy    Europe   \n",
       "1    2020-01-01        0.0         0.0        NaN    Italy    Europe   \n",
       "2    2020-01-02        0.0         0.0        NaN    Italy    Europe   \n",
       "3    2020-01-03        0.0         0.0        NaN    Italy    Europe   \n",
       "4    2020-01-04        0.0         0.0        NaN    Italy    Europe   \n",
       "..          ...        ...         ...        ...      ...       ...   \n",
       "243  2020-08-30     1444.0         1.0    53541.0    Italy    Europe   \n",
       "244  2020-08-31     1365.0         4.0    42583.0    Italy    Europe   \n",
       "245  2020-09-01      996.0         6.0    54395.0    Italy    Europe   \n",
       "246  2020-09-02      975.0         8.0        NaN    Italy    Europe   \n",
       "247  2020-09-03     1326.0         6.0        NaN    Italy    Europe   \n",
       "\n",
       "     population  life_expectancy  hospital_beds_per_thousand  gdp_per_capita  \n",
       "0    60461828.0            83.51                        3.18       35220.084  \n",
       "1    60461828.0            83.51                        3.18       35220.084  \n",
       "2    60461828.0            83.51                        3.18       35220.084  \n",
       "3    60461828.0            83.51                        3.18       35220.084  \n",
       "4    60461828.0            83.51                        3.18       35220.084  \n",
       "..          ...              ...                         ...             ...  \n",
       "243  60461828.0            83.51                        3.18       35220.084  \n",
       "244  60461828.0            83.51                        3.18       35220.084  \n",
       "245  60461828.0            83.51                        3.18       35220.084  \n",
       "246  60461828.0            83.51                        3.18       35220.084  \n",
       "247  60461828.0            83.51                        3.18       35220.084  \n",
       "\n",
       "[248 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 두데이터가 합쳐져 더 큰 데이터셋을 구성하게 되었고 이를 이용해 이전에는 구하지 못했던 보다 큰 범위의 평균을 구할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['cases_per_million'] = merged_df.total_cases * 1e6 / merged_df.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['deaths_per_million'] = merged_df.total_deaths * 1e6 / merged_df.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['tests_per_million'] = merged_df.total_tests * 1e6 / merged_df.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터를 다시 파일로 저장하기\n",
    "\n",
    "분석과 열 추가가 완료된 데이터는 새롭게 파일에 저장해야 합니다. <br>\n",
    "그렇지 않으면 Jupyter Notebook을 종료함과 동시에 데이터가 손실될 것입니다. <br>\n",
    "데이터를 저장하기 전에 저장하기를 원하는 열로만 구성된 데이터프레임을 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = merged_df[['date',\n",
    "                       'new_cases', \n",
    "                       'total_cases', \n",
    "                       'new_deaths', \n",
    "                       'total_deaths', \n",
    "                       'new_tests', \n",
    "                       'total_tests', \n",
    "                       'cases_per_million', \n",
    "                       'deaths_per_million', \n",
    "                       'tests_per_million']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터프레임의 데이터를 파일로 저장하기 위해 `to_csv`함수를 사용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('results.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`to_csv` 함수는 인덱스를 하나의 열로 구성하여 넣는 것을 기본값으로 가지고 있습니다.<br>\n",
    "`index=None` 를 사용해서 이 동작을 멈출 수 있습니다. <br>\n",
    "\n",
    "이제 `results.csv` 가 생성되었고 CSV 형태로 저장되어 있는 것을 알 수 있습니다:\n",
    "\n",
    "```\n",
    "date,new_cases,total_cases,new_deaths,total_deaths,new_tests,total_tests,cases_per_million,deaths_per_million,tests_per_million\n",
    "2020-02-27,78.0,400.0,1.0,12.0,,,6.61574439992122,0.1984723319976366,\n",
    "2020-02-28,250.0,650.0,5.0,17.0,,,10.750584649871982,0.28116913699665186,\n",
    "2020-02-29,238.0,888.0,4.0,21.0,,,14.686952567825108,0.34732658099586405,\n",
    "2020-03-01,240.0,1128.0,8.0,29.0,,,18.656399207777838,0.47964146899428844,\n",
    "2020-03-02,561.0,1689.0,6.0,35.0,,,27.93498072866735,0.5788776349931067,\n",
    "2020-03-03,347.0,2036.0,17.0,52.0,,,33.67413899559901,0.8600467719897585,\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Pandas Visualization\n",
    "\n",
    "보통 `matplotlib`이나 `seaborn` 라이브러리를 사용해서 그래프를 만들지만,\n",
    "Pandas 데이터프레임이나 Series도 `plot` 함수를 제공해서 시각화 할 수 있습니다.<br>\n",
    "<br>\n",
    "시계열에 따른 그래프를 그려보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.new_cases.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 그래프가 전체적인 추세를 보여주고 있지만, x-축 데이터가 없기 때문에, 언제 정점이 발생하는지 알기 어렵습니다.<br>\n",
    "`date`열의 인덱스를 사용해서 x축 정보를 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인덱스를 통해 해당 날짜를 알아낼 수 있고 `loc`을 이용해 해당 날짜의 데이터를 추출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.loc['2020-09-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신규 확진자와 신규 사망자를 그래프로 그려보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.new_cases.plot()\n",
    "result_df.new_deaths.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 감염자와 총 사망자를 비교할 수도 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.total_cases.plot()\n",
    "result_df.total_deaths.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사망률과 양성 결과율이 시간에 따라 어떻게 바뀌는지도 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_rate = result_df.total_deaths / result_df.total_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_rate.plot(title='Death Rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_rates = result_df.total_cases / result_df.total_tests\n",
    "positive_rates.plot(title='Positive Rate');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로, 월별로 신규확진자 발생을 막대그래프를 통해서 그려보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_month_df.new_cases.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_month_df.new_tests.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Further Reading\n",
    "\n",
    "본 튜토리얼에서는 다음 주제를 다뤘습니다.:\n",
    "- CSV 파일을 Pandas Dataframe으로 읽어오기\n",
    "- Pandas Dataframe을 통해 데이터 처리하기\n",
    "- 데이터 쿼리, 정렬, 분석하기\n",
    "- 데이터를 합치기, 분리하기\n",
    "- 데이터에서 유용한 정보 추출하기\n",
    "- 기본적인 막대그래프와 꺾은선 그래프 만들기\n",
    "- Dataframe 파일을 CSV 파일로 저장하기\n",
    "\n",
    "추가적인 Pandas에 대한 자료는 다음 웹페이지에서 확인해볼 수 있습니다.\n",
    "\n",
    "* Pandas: https://pandas.pydata.org/docs/user_guide/index.html\n",
    "* Data Analysis (book by Wes McKinney - creator of Pandas): https://www.oreilly.com/library/view/python-for-data/9781491957653/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "dcc17d9fae1840219df203148af72cc2b9310289ac3e42c5ae7f8f99baad0909"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
